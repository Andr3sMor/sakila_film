name: CICD Pipeline AWS Glue Workflow

on:
  push:
    branches: [main]
    paths:
      - glue_scripts/*.py
      - requirements.txt
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * *"  # Ejecuta cada día a las 2 AM hora Colombia (-5 UTC)

jobs:
  # --------------------------------------------------
  # 1️⃣ Pruebas unitarias
  # --------------------------------------------------
  test:
    name: Run ETL Unit Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: 3.9

      - name: Install dependencies
        run: |
          python3 -m venv env
          source env/bin/activate
          pip install pytest boto3 pyarrow pandas holidays

      - name: Run unit tests
        run: |
          source env/bin/activate
          pytest tests/ -v

  # --------------------------------------------------
  # 2️⃣ Despliegue y orquestación del Workflow de Glue
  # --------------------------------------------------
  deploy:
    name: Deploy Glue Workflow
    runs-on: ubuntu-latest
    needs: test

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload Glue scripts to S3
        run: |
          BUCKET=${{ secrets.S3_BUCKET_SCRIPTS }}
          VERSION=$(date +%Y%m%d%H%M%S)
          echo "Subiendo scripts ETL a s3://$BUCKET..."
          
          for file in glue_scripts/*.py; do
            JOB=$(basename "$file" .py)
            DEST="s3://$BUCKET/$JOB/$VERSION/$JOB.py"
            aws s3 cp "$file" "$DEST"
            echo "$JOB=$DEST" >> $GITHUB_ENV
            echo "✅ Subido: $DEST"
          done

      - name: Create or Update Glue Jobs and Workflow
        run: |
          echo "Creando o actualizando jobs y workflow..."
          python3 <<'EOF'
          import boto3, os

          glue = boto3.client('glue')
          ROLE_ARN = os.environ['AWS_GLUE_ROLE_ARN']
          WORKFLOW_NAME = "sakila_data_pipeline"
          TEMP_DIR = "s3://cmjm-datalake/temp/"

          jobs = [
              ("sakila-etl-fact-rental", os.getenv("etl_rental")),
              ("sakila-etl-dim-customer", os.getenv("dim_customer")),
              ("sakila-etl-dim-film", os.getenv("dim_film")),
              ("sakila-etl-dim-store", os.getenv("dim_store")),
              ("sakila-etl-dim-date", os.getenv("dim_date")),
          ]

          # --- Crear o actualizar Glue Jobs ---
          for job_name, script in jobs:
              if not script:
                  continue
              try:
                  glue.get_job(JobName=job_name)
                  print(f"Actualizando job {job_name}...")
                  glue.update_job(
                      JobName=job_name,
                      JobUpdate={
                          "Role": ROLE_ARN,
                          "Command": {"Name": "glueetl", "ScriptLocation": script, "PythonVersion": "3"},
                          "GlueVersion": "4.0",
                          "DefaultArguments": {
                              "--TempDir": TEMP_DIR,
                              "--job-bookmark-option": "job-bookmark-enable"
                          },
                          "NumberOfWorkers": 2,
                          "WorkerType": "G.1X"
                      }
                  )
              except glue.exceptions.EntityNotFoundException:
                  print(f"Creando job {job_name}...")
                  glue.create_job(
                      Name=job_name,
                      Role=ROLE_ARN,
                      Command={"Name": "glueetl", "ScriptLocation": script, "PythonVersion": "3"},
                      GlueVersion="4.0",
                      DefaultArguments={
                          "--TempDir": TEMP_DIR,
                          "--job-bookmark-option": "job-bookmark-enable"
                      },
                      NumberOfWorkers=2,
                      WorkerType="G.1X"
                  )

          # --- Crear workflow si no existe ---
          try:
              glue.get_workflow(Name=WORKFLOW_NAME)
              print(f"Workflow {WORKFLOW_NAME} ya existe.")
          except glue.exceptions.EntityNotFoundException:
              glue.create_workflow(Name=WORKFLOW_NAME, Description="Pipeline Sakila ETL completo")
              print(f"Workflow {WORKFLOW_NAME} creado.")

          # --- Crear triggers secuenciales ---
          def create_trigger(name, job_name, dependency=None):
              try:
                  glue.get_trigger(Name=name)
                  print(f"Trigger {name} ya existe.")
              except glue.exceptions.EntityNotFoundException:
                  predicate = None
                  if dependency:
                      predicate = {
                          "Logical": "AND",
                          "Conditions": [{"JobName": dependency, "State": "SUCCEEDED"}]
                      }
                      trigger_type = "CONDITIONAL"
                  else:
                      trigger_type = "ON_DEMAND"
                  
                  glue.create_trigger(
                      Name=name,
                      Type=trigger_type,
                      Actions=[{"JobName": job_name}],
                      WorkflowName=WORKFLOW_NAME,
                      StartOnCreation=True,
                      Predicate=predicate
                  )
                  print(f"Trigger {name} creado.")

          # Orden secuencial
          order = [
              ("t1_rental", "sakila-etl-fact-rental", None),
              ("t2_dim_customer", "sakila-etl-dim-customer", "sakila-etl-fact-rental"),
              ("t3_dim_film", "sakila-etl-dim-film", "sakila-etl-dim-customer"),
              ("t4_dim_store", "sakila-etl-dim-store", "sakila-etl-dim-film"),
              ("t5_dim_date", "sakila-etl-dim-date", "sakila-etl-dim-store"),
          ]

          for tname, job, dep in order:
              create_trigger(tname, job, dep)

          print("✅ Glue Workflow actualizado correctamente.")
          EOF

      - name: Launch Glue Workflow
        run: |
          echo "Iniciando ejecución del workflow completo..."
          aws glue start-workflow-run --name sakila_data_pipeline
          echo "✅ Workflow lanzado correctamente."
